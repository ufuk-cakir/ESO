{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "datapath = \"/Users/ufuk/Research/AIMS/Project Repo/eso/data/Saved_Data/preprocessed\"\n",
    "\n",
    "with open(datapath + \"/X.pkl\", \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "with open(datapath + \"/Y.pkl\", \"rb\") as f:\n",
    "    Y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ufuk/Research/AIMS/Project Repo/eso/src/eso/model/model_test.ipynb Zelle 2\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ufuk/Research/AIMS/Project%20Repo/eso/src/eso/model/model_test.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m datapath \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Users/ufuk/Research/AIMS/Project Repo/eso/data/Saved_Data/preprocessed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ufuk/Research/AIMS/Project%20Repo/eso/src/eso/model/model_test.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(datapath \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/X.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ufuk/Research/AIMS/Project%20Repo/eso/src/eso/model/model_test.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     X \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ufuk/Research/AIMS/Project%20Repo/eso/src/eso/model/model_test.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(datapath \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/Y.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ufuk/Research/AIMS/Project%20Repo/eso/src/eso/model/model_test.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     Y\u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2424, 128, 76), (2424,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_conv_output_dim(layer, input_dim):\n",
    "    \"\"\"Calculate output dimension of a CNN layer\"\"\"\n",
    "    kernel_size = layer.kernel_size\n",
    "    stride = layer.stride\n",
    "    padding = layer.padding\n",
    "    dilation = layer.dilation\n",
    "\n",
    "    input_channels, input_height, input_width = input_dim\n",
    "\n",
    "    output_channels = layer.out_channels\n",
    "    output_height = (\n",
    "        input_height + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1\n",
    "    ) / stride[0] + 1\n",
    "    output_width = (\n",
    "        input_width + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1\n",
    "    ) / stride[1] + 1\n",
    "\n",
    "    return (output_channels, int(output_height), int(output_width))\n",
    "\n",
    "\n",
    "class BaseCNN(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(BaseCNN, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        n_channels, height, width = input_shape\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(1),\n",
    "        )\n",
    "\n",
    "        self.cnn_output_dim = self._calc_cnn_output_dim()\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(np.prod(self.cnn_output_dim), 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 2),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            x = x.unsqueeze(1)\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, np.prod(self.cnn_output_dim))\n",
    "        x = self.fully_connected(x)\n",
    "        return x\n",
    "\n",
    "    def _calc_cnn_output_dim(self):\n",
    "        \"\"\"Calculate output dimension of the CNN part of the network\"\"\"\n",
    "\n",
    "        output_dim = get_conv_output_dim(self.conv[0], self.input_shape)\n",
    "        for layer in self.conv[1:]:\n",
    "            # Check if layer is a convolutional layer\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                output_dim = get_conv_output_dim(layer, output_dim)\n",
    "\n",
    "        return output_dim\n",
    "\n",
    "\n",
    "class Model:\n",
    "    \"\"\"Model class.\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        self.cnn = BaseCNN(input_shape)\n",
    "        # self.logger.info(\"Initializing Model...\")\n",
    "        # Get Device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def get_number_of_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "    def train_model(\n",
    "        self, n_epochs, train_loader, optimizer, criterion, save_path=None, verbose=True\n",
    "    ):\n",
    "        print(\"Training\")\n",
    "\n",
    "        self.cnn.to(self.device)\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        val_accs = []\n",
    "        best_val_acc = 0\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            print(\"Epoch: \", epoch)\n",
    "            for batch_inputs, batch_targets in train_loader:\n",
    "                batch_inputs, batch_targets = (\n",
    "                    batch_inputs.to(self.device),\n",
    "                    batch_targets.to(self.device),\n",
    "                )\n",
    "                # Reset gradients\n",
    "                optimizer.zero_grad()\n",
    "                # Forward pass\n",
    "                batch_preds = self.cnn.forward(batch_inputs)\n",
    "                # Compute loss\n",
    "                loss = criterion(batch_preds, batch_targets)\n",
    "                # Backward and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.item())\n",
    "        return train_losses\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "    def evaluate(self, loader, criterion):\n",
    "        self.cnn.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            for batch_inputs, batch_targets in loader:\n",
    "                batch_inputs, batch_targets = (\n",
    "                    batch_inputs.to(self.device),\n",
    "                    batch_targets.to(self.device),\n",
    "                )\n",
    "                batch_preds = self.cnn.forward(batch_inputs)\n",
    "\n",
    "                total_loss += criterion(batch_preds, batch_targets).item()\n",
    "                correct += (batch_preds.argmax(dim=1) == batch_targets).sum().item()\n",
    "            average_loss = total_loss / len(loader)\n",
    "            accuracy = correct / len(loader.dataset)\n",
    "        self.cnn.train()\n",
    "        return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2424, 128, 76)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 76])\n"
     ]
    }
   ],
   "source": [
    "m = Model(input_shape=(1, X.shape[1], X.shape[2]))\n",
    "test = torch.from_numpy(X[0]).float()\n",
    "test = test.unsqueeze(0)\n",
    "print(test.shape)\n",
    "m(test)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Encode class labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "label_classes = dict(\n",
    "    zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))\n",
    ")\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_train_tensor = torch.Tensor(y_train_encoded).long()\n",
    "y_test_tensor = torch.Tensor(y_test_encoded).long()\n",
    "\n",
    "\n",
    "# Create one-hot encodings for class labels\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_train_onehot = torch.zeros(len(y_train_encoded), num_classes)\n",
    "y_train_onehot.scatter_(1, y_train_tensor.view(-1, 1), 1)\n",
    "\n",
    "\n",
    "# Create datasets and data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1939, 128, 76)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 3, 3], expected input[1, 32, 128, 76] to have 1 channels, but got 32 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/ufuk/Research/AIMS/Project Repo/eso/src/eso/model/model_test.ipynb Zelle 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ufuk/Research/AIMS/Project%20Repo/eso/src/eso/model/model_test.ipynb#Y111sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m m\u001b[39m.\u001b[39;49mtrain(\u001b[39m5\u001b[39;49m, X_train \u001b[39m=\u001b[39;49m X_train, Y_train \u001b[39m=\u001b[39;49m y_train_encoded)\n",
      "File \u001b[0;32m~/Research/AIMS/Project Repo/eso/src/eso/model/model.py:66\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, n_epochs, X_train, Y_train, save_path, verbose)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     65\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m batch_preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn\u001b[39m.\u001b[39;49mforward(batch_inputs)\n\u001b[1;32m     67\u001b[0m \u001b[39m# Compute loss\u001b[39;00m\n\u001b[1;32m     68\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(batch_preds, batch_targets)\n",
      "File \u001b[0;32m~/Research/AIMS/Project Repo/eso/src/eso/model/cnn.py:77\u001b[0m, in \u001b[0;36mBaseCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     75\u001b[0m     \u001b[39m#if len(x.shape) == 3:\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[39m#    x = x.unsqueeze(1)\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)\n\u001b[1;32m     78\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, np\u001b[39m.\u001b[39mprod(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcnn_output_dim))\n\u001b[1;32m     79\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfully_connected(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/eso/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/eso/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/eso/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/eso/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/eso/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 3, 3], expected input[1, 32, 128, 76] to have 1 channels, but got 32 channels instead"
     ]
    }
   ],
   "source": [
    "m.train(5, X_train=X_train, Y_train=y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Model.train() missing 5 required positional arguments: 'n_epochs', 'X_train', 'Y_train', 'optimizer', and 'criterion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ufuk/Research/AIMS/Project Repo/eso/src/eso/model/model_test.ipynb Zelle 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ufuk/Research/AIMS/Project%20Repo/eso/src/eso/model/model_test.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m m\u001b[39m.\u001b[39;49mtrain()\n",
      "\u001b[0;31mTypeError\u001b[0m: Model.train() missing 5 required positional arguments: 'n_epochs', 'X_train', 'Y_train', 'optimizer', and 'criterion'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 76])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4578, 0.5422]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model(input_shape=(1, X.shape[1], X.shape[2]))\n",
    "test = torch.from_numpy(X[0]).float()\n",
    "test = test.unsqueeze(0)\n",
    "print(test.shape)\n",
    "m(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 76])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5028, 0.4972]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Model(input_shape=(1, X.shape[1], X.shape[2]))\n",
    "test = torch.Tensor(X[0])\n",
    "test = test.unsqueeze(0)\n",
    "print(test.shape)\n",
    "m(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "\n",
    "# Encode class labels to integers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "label_classes = dict(\n",
    "    zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))\n",
    ")\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_train_tensor = torch.Tensor(y_train_encoded).long()\n",
    "y_test_tensor = torch.Tensor(y_test_encoded).long()\n",
    "\n",
    "\n",
    "# Create one-hot encodings for class labels\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_train_onehot = torch.zeros(len(y_train_encoded), num_classes)\n",
    "y_train_onehot.scatter_(1, y_train_tensor.view(-1, 1), 1)\n",
    "\n",
    "\n",
    "# Create datasets and data loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6969032883644104,\n",
       " 0.46951162815093994,\n",
       " 0.5320115685462952,\n",
       " 0.5007615685462952,\n",
       " 0.5632616281509399,\n",
       " 0.5007616281509399,\n",
       " 0.34451165795326233,\n",
       " 0.5945116281509399,\n",
       " 0.5320115685462952,\n",
       " 0.7195115685462952,\n",
       " 0.43826159834861755,\n",
       " 0.31326165795326233,\n",
       " 0.43826162815093994,\n",
       " 0.46951165795326233,\n",
       " 0.40701165795326233,\n",
       " 0.5007616281509399,\n",
       " 0.5007616281509399,\n",
       " 0.5320115685462952,\n",
       " 0.37576159834861755,\n",
       " 0.43826165795326233,\n",
       " 0.5632616877555847,\n",
       " 0.6882616877555847,\n",
       " 0.46951159834861755,\n",
       " 0.5007616281509399,\n",
       " 0.5007616281509399,\n",
       " 0.46951162815093994,\n",
       " 0.5945116281509399,\n",
       " 0.46951162815093994,\n",
       " 0.46951162815093994,\n",
       " 0.5007615685462952,\n",
       " 0.5007616281509399,\n",
       " 0.43826162815093994,\n",
       " 0.6257616877555847,\n",
       " 0.5320116281509399,\n",
       " 0.46951159834861755,\n",
       " 0.46951159834861755,\n",
       " 0.43826165795326233,\n",
       " 0.43826159834861755,\n",
       " 0.5007615685462952,\n",
       " 0.5320115685462952,\n",
       " 0.5320116281509399,\n",
       " 0.46951165795326233,\n",
       " 0.5320115685462952,\n",
       " 0.5320116281509399,\n",
       " 0.43826162815093994,\n",
       " 0.6257616877555847,\n",
       " 0.5007616281509399,\n",
       " 0.5945116281509399,\n",
       " 0.5945116281509399,\n",
       " 0.5632616281509399,\n",
       " 0.6257616877555847,\n",
       " 0.5007616281509399,\n",
       " 0.5007616281509399,\n",
       " 0.5007616877555847,\n",
       " 0.5007616281509399,\n",
       " 0.5320115685462952,\n",
       " 0.43826162815093994,\n",
       " 0.5320116281509399,\n",
       " 0.5320115685462952,\n",
       " 0.5007615685462952,\n",
       " 0.5237879157066345,\n",
       " 0.40701162815093994,\n",
       " 0.46951165795326233,\n",
       " 0.43826162815093994,\n",
       " 0.5320116281509399,\n",
       " 0.5945116877555847,\n",
       " 0.5007616281509399,\n",
       " 0.46951165795326233,\n",
       " 0.5007615685462952,\n",
       " 0.46951162815093994,\n",
       " 0.5632616281509399,\n",
       " 0.40701159834861755,\n",
       " 0.5945115685462952,\n",
       " 0.5007616281509399,\n",
       " 0.40701165795326233,\n",
       " 0.5632616281509399,\n",
       " 0.46951165795326233,\n",
       " 0.46951165795326233,\n",
       " 0.5007616281509399,\n",
       " 0.43826165795326233,\n",
       " 0.5320116281509399,\n",
       " 0.5632616281509399,\n",
       " 0.5320116877555847,\n",
       " 0.5945116281509399,\n",
       " 0.5320116281509399,\n",
       " 0.40701165795326233,\n",
       " 0.5320115685462952,\n",
       " 0.40701159834861755,\n",
       " 0.5007616281509399,\n",
       " 0.5945116877555847,\n",
       " 0.43826159834861755,\n",
       " 0.5320115685462952,\n",
       " 0.46951162815093994,\n",
       " 0.43826162815093994,\n",
       " 0.46951159834861755,\n",
       " 0.5007616281509399,\n",
       " 0.37576165795326233,\n",
       " 0.5320116281509399,\n",
       " 0.5632615685462952,\n",
       " 0.5007615685462952,\n",
       " 0.46951162815093994,\n",
       " 0.37576165795326233,\n",
       " 0.5945116877555847,\n",
       " 0.7195116877555847,\n",
       " 0.5007616281509399,\n",
       " 0.46951162815093994,\n",
       " 0.5007615685462952,\n",
       " 0.6570116281509399,\n",
       " 0.40701162815093994,\n",
       " 0.5007615685462952,\n",
       " 0.5007616281509399,\n",
       " 0.5945116877555847,\n",
       " 0.46951162815093994,\n",
       " 0.5320116877555847,\n",
       " 0.7507616877555847,\n",
       " 0.5632616281509399,\n",
       " 0.5945116281509399,\n",
       " 0.43826165795326233,\n",
       " 0.5320116281509399,\n",
       " 0.40701162815093994,\n",
       " 0.5320115685462952,\n",
       " 0.47115635871887207,\n",
       " 0.5632616281509399,\n",
       " 0.5320115685462952,\n",
       " 0.43826159834861755,\n",
       " 0.5632616877555847,\n",
       " 0.5320116281509399,\n",
       " 0.46951159834861755,\n",
       " 0.46951159834861755,\n",
       " 0.5320116281509399,\n",
       " 0.5007616281509399,\n",
       " 0.5632616877555847,\n",
       " 0.6570116877555847,\n",
       " 0.5320116281509399,\n",
       " 0.5320116281509399,\n",
       " 0.5007616281509399,\n",
       " 0.5007616281509399,\n",
       " 0.5632616281509399,\n",
       " 0.5945116877555847,\n",
       " 0.40701165795326233,\n",
       " 0.46951165795326233,\n",
       " 0.5632616281509399,\n",
       " 0.5320116281509399,\n",
       " 0.5632615685462952,\n",
       " 0.46951165795326233,\n",
       " 0.46951165795326233,\n",
       " 0.46951159834861755,\n",
       " 0.5007616281509399,\n",
       " 0.43826159834861755,\n",
       " 0.5945116877555847,\n",
       " 0.43826162815093994,\n",
       " 0.5007616281509399,\n",
       " 0.6882616877555847,\n",
       " 0.46951162815093994,\n",
       " 0.46951162815093994,\n",
       " 0.46951165795326233,\n",
       " 0.46951165795326233,\n",
       " 0.5632616281509399,\n",
       " 0.43826159834861755,\n",
       " 0.5320115685462952,\n",
       " 0.5632616281509399,\n",
       " 0.5632616281509399,\n",
       " 0.46951165795326233,\n",
       " 0.5007616281509399,\n",
       " 0.37576162815093994,\n",
       " 0.4695116877555847,\n",
       " 0.46951165795326233,\n",
       " 0.46951159834861755,\n",
       " 0.5945116877555847,\n",
       " 0.5320115685462952,\n",
       " 0.5320116281509399,\n",
       " 0.40701165795326233,\n",
       " 0.5007616281509399,\n",
       " 0.40701162815093994,\n",
       " 0.5007616281509399,\n",
       " 0.37576162815093994,\n",
       " 0.5007616281509399,\n",
       " 0.5320115685462952,\n",
       " 0.40701162815093994,\n",
       " 0.5945116281509399,\n",
       " 0.6257615685462952,\n",
       " 0.46951159834861755,\n",
       " 0.4711563289165497]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.train_model(\n",
    "    n_epochs=3,\n",
    "    train_loader=train_loader,\n",
    "    optimizer=torch.optim.Adam(m.cnn.parameters(), lr=0.001),\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5402147453278303, 0.7938144329896907)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(test_loader, nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18692642"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_number_of_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([32, 32, 125, 73])\n",
      "Predicted shape: (32, 125, 73)\n",
      "Actual shape: torch.Size([5, 32, 125, 73])\n",
      "Test Accuracy: 82.68%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "cnn.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_inputs, batch_labels in test_loader:\n",
    "        batch_inputs = batch_inputs.unsqueeze(1)\n",
    "        outputs = cnn(batch_inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += len(batch_inputs)\n",
    "        correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(batch_labels, predicted))\n",
    "        precision_scores.append(precision_score(batch_labels, predicted))\n",
    "        recall_scores.append(recall_score(batch_labels, predicted))\n",
    "        f1_scores.append(f1_score(batch_labels, predicted))\n",
    "        confusion_matrices.append(confusion_matrix(batch_labels, predicted))\n",
    "\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {100 * accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
