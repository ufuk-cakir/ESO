{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0de767b-e46a-4573-9320-ff96ea0c5afa",
   "metadata": {},
   "source": [
    "## Example 3: Inference, Number of trainable parameters, Number of FLOPs, Number of MACs\n",
    "\n",
    "* Perform inference on Audio data with trained and saved baseline/ESO models\n",
    "* Compare number of trainable parameters between baseline and ESO classifiers\n",
    "* Compare number of FLOPs between baseline and ESO classifiers\n",
    "* Compare number of MACs between baseline and ESO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6c33a-cfa7-4e35-911c-293fd0578181",
   "metadata": {},
   "source": [
    "### Importing required libraries\n",
    "\n",
    "In order to calculate the number of trainable parameters, FLOPs and MACS we can make use of the \n",
    "[calflops package](https://github.com/MrYxJ/calculate-flops.pytorch). calflops requires the [transformers](https://pypi.org/project/transformers/) package to be installed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce9d2e3d-9d2f-40ee-9dac-0619b2f66fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 10:54:30.131598: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-09 10:54:30.333039: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-09 10:54:33.339401: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/aaron-joel/anaconda3/envs/eso/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from eso.model.model import Model\n",
    "from eso.utils.preprocessing import Preprocessing\n",
    "from eso import ESO\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from calflops import calculate_flops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d0687-e16c-49ba-932e-631ff1f70837",
   "metadata": {},
   "source": [
    "### Helper Functions for Inference on saved models\n",
    "\n",
    "The aim of this experiment is to perform inference on audio data using saved baseline and ESO models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17a9322e-4413-42db-9b18-eaf5552408a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The program will use: cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"The program will use: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3f22943-2fe3-4316-acf0-47ed00c845d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "POSITIVE_CLASS = \"gibbon\"\n",
    "NEGATIVE_CLASS = \"no-gibbon\"\n",
    "\n",
    "PREPROCESSING_ARGS= {\n",
    "        \"lowpass_cutoff\": 2000,\n",
    "        \"downsample_rate\": 4800,\n",
    "        \"nyquist_rate\": 2400,\n",
    "        \"segment_duration\": 4,\n",
    "        \"nb_negative_class\": 20,\n",
    "        \"file_type\": \"svl\",\n",
    "        \"audio_extension\": \".wav\",\n",
    "        \"n_fft\": 1024,\n",
    "        \"hop_length\": 256,\n",
    "        \"n_mels\": 128,\n",
    "        \"f_min\": 4000,\n",
    "        \"f_max\": 9000,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319031d8-816d-42c7-b410-d1d971cf5d0f",
   "metadata": {},
   "source": [
    "Specify the paths for saved models and audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58838966-9557-4787-a606-566a09c0c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = Path('/home/aaron-joel/Documents/Examples/results')\n",
    "# saved baseline CNN model path\n",
    "BASELINE_CNN_STATE_PATH = RESULTS_PATH / 'baseline_cnn_state.pth'\n",
    "# saved ESO CNN model path\n",
    "ESO_CNN_STATE_PATH = RESULTS_PATH / 'chromosome_cnn_state.pth'\n",
    "# saved path of best performing chromosome\n",
    "CHROMOSOME_PKL_PATH = RESULTS_PATH / 'eso_chromosome.pkl'\n",
    "# Audio data folder (A small dataset for demonstration purpose only)\n",
    "SPECIES_FOLDER = Path('/home/aaron-joel/Documents/Examples/SmallData')\n",
    "# Text file containing the names of audio files for testing\n",
    "AUDIO_NAMES_TXT = SPECIES_FOLDER / 'DataFiles' / 'test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca7f8e51-7412-4853-89f8-c8760e86f26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/aaron-joel/Documents/Examples/SmallData/DataFiles/test.txt')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_NAMES_TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "211b260c-a80f-4015-a4e9-855fa62cd2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for prediction\n",
    "def _predict(model, X, batch_size=128, device=DEVICE):\n",
    "    prediction_list = []\n",
    "    \n",
    "    # convert input X into float tensor\n",
    "    X_tensor = torch.from_numpy(X).float()\n",
    "    \n",
    "    # Check that input has proper shape/reshape\n",
    "    if len(X_tensor.shape) == 3:\n",
    "        X_tensor = X_tensor.unsqueeze(1)\n",
    "        \n",
    "    # create dataloader object\n",
    "    loader = torch.utils.data.DataLoader(dataset=X_tensor, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # put model on device and set it on eval mode\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Perform the inference\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            prediction_list.append(pred.cpu())\n",
    "    softmax_prediction = [i.detach().numpy() for i in prediction_list]\n",
    "    return np.vstack(softmax_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e421c599-d60a-4051-afd7-e096e4bdd737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for creating dataset for selected model given \n",
    "# audio data and preprocessing arguments\n",
    "def _create_data(model):\n",
    "    \"\"\"\n",
    "    Create the dataset for the model\n",
    "\n",
    "    Args:\n",
    "        model: str, 'baseline' or 'eso'\n",
    "\n",
    "    Returns:\n",
    "        X: np.array, shape (n_samples, n_features)\n",
    "        Y: np.array, shape (n_samples, )\n",
    "        dataset_creation_time: float, time it took to create the dataset\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    if model == 'baseline':\n",
    "        apply_preprocessing = True\n",
    "    elif model == 'eso':\n",
    "        apply_preprocessing = False\n",
    "    else:\n",
    "        raise ValueError(\"Model must be either 'baseline' or 'eso'\")\n",
    "    print(f\"--- Creating Dataset for model: {model} ---\")\n",
    "    \n",
    "    # Instantiate a Preprocessing object and create the dataset for chosen model\n",
    "    preprocessor = Preprocessing(**PREPROCESSING_ARGS,\n",
    "                                 apply_preprocessing=apply_preprocessing,\n",
    "                                 species_folder=SPECIES_FOLDER,\n",
    "                                 positive_class=POSITIVE_CLASS,\n",
    "                                 negative_class=NEGATIVE_CLASS)\n",
    "    \n",
    "    X, Y = preprocessor.create_dataset(verbose=False,\n",
    "                                       file_names=AUDIO_NAMES_TXT,\n",
    "                                       augmentation=False,\n",
    "                                       annotation_folder=\"Annotations\",\n",
    "                                       sufix_file='.svl')\n",
    "    \n",
    "    dataset_creation_time = time.time() - start_time\n",
    "    print(f\"--- Dataset created in {dataset_creation_time} seconds ---\")\n",
    "    return (X, Y, dataset_creation_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d48df46c-6030-4661-87fe-aa44a2753c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use helper in this function to make model prediction\n",
    "def model_prediction(X, model, batch_size=128, device=DEVICE):\n",
    "    '''\n",
    "    This function is used to make prediction given input data (X),\n",
    "    and selected model.\n",
    "\n",
    "    Args:\n",
    "        X: np.array shape (n_samples, n_features)\n",
    "        model: str, 'baseline' or 'eso'\n",
    "        device: torch.device, 'cpu' or 'cuda'\n",
    "\n",
    "    Returns:\n",
    "        Y_pred: np.array shape (n_samples,)\n",
    "        prediction_time: time it took to make prediction.\n",
    "    '''\n",
    "    # starting time\n",
    "    start_time = time.time()\n",
    "    # Model loading depends on selected model\n",
    "    if model == 'baseline':\n",
    "        baseline_model = Model.load_cnn(cnn_dict=BASELINE_CNN_STATE_PATH, device=device)\n",
    "        Y_pred = _predict(model=baseline_model, X=X, batch_size=batch_size, device=device)\n",
    "        prediction_time = time.time() - start_time\n",
    "        print(f\"--- Predicted Baseline in {prediction_time} seconds ---\")\n",
    "        return (Y_pred, prediction_time)\n",
    "    elif model == 'eso':\n",
    "        eso_model = Model.load_cnn(cnn_dict=ESO_CNN_STATE_PATH, device=device)\n",
    "        # load eso chromosome from file to numpy and use it to create relevant dataset\n",
    "        eso_chromosome = np.load(CHROMOSOME_PKL_PATH, allow_pickle=True)\n",
    "        X = eso_chromosome._create_dataset(X)\n",
    "        # Make prediction for 'eso-created dataset X'\n",
    "        Y_pred = _predict(model=eso_model, X=X, batch_size=batch_size, device=device)\n",
    "        prediction_time = time.time() - start_time\n",
    "        print(f\"--- Predicted ESO in {prediction_time} seconds ---\")\n",
    "        return (Y_pred, prediction_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c954a-d1ca-4c7f-a43e-d4454b31f0a3",
   "metadata": {},
   "source": [
    "### Helper Functions for FLOPs, MACs Number of Trainable Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a88bc46f-61cc-4953-abdf-24a84d69876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_flops(model, batch_size=1, device=DEVICE):\n",
    "    '''\n",
    "    This function takes the model type and batch_size as inputs and\n",
    "    returns the number of flops, macs and trainable parameters.\n",
    "\n",
    "    Args:\n",
    "        model: str, 'baseline' or 'eso'\n",
    "        device: torch.device,  'cpu' or 'cuda'\n",
    "        batch_size: int, default to 1\n",
    "\n",
    "    Returns:\n",
    "        flops: float, number of floating point number per second\n",
    "        macs: number of multiply-accumulate operations\n",
    "        params: int, number of trainable parameters\n",
    "    '''\n",
    "    if model == 'baseline':\n",
    "        baseline_model = Model.load_cnn(cnn_dict=BASELINE_CNN_STATE_PATH, device=device)\n",
    "        input_shape = (batch_size, *baseline_model.input_shape)\n",
    "        # Use calculate_flops from calflops to perform the calc\n",
    "        flops, macs, params = calculate_flops(model=baseline_model,\n",
    "                                              input_shape=input_shape,\n",
    "                                              print_results=False,\n",
    "                                              output_as_string=False)\n",
    "        return (flops, macs, params)\n",
    "    elif model == 'eso':\n",
    "        eso_model = Model.load_cnn(cnn_dict=ESO_CNN_STATE_PATH, device=device)\n",
    "        input_shape = (batch_size, *eso_model.input_shape)\n",
    "        flops, macs, params = calculate_flops(model=eso_model,\n",
    "                                              input_shape=input_shape,\n",
    "                                              print_results=False,\n",
    "                                              output_as_string=False)\n",
    "        return (flops, macs, params)\n",
    "    else:\n",
    "        raise ValueError(\"Model must be either 'baseline' or 'eso'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6944136-59c8-4791-adb0-4ce5a11c6d70",
   "metadata": {},
   "source": [
    "### Main function for executing inference and calculating flops, macs and number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45dfbd74-55ca-46c2-9c5e-3c1c5fde1b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ## Inference with baseline\n",
    "    \n",
    "    # Step 1: create dataset\n",
    "    X, Y, dataset_creation_time_base = _create_data('baseline')\n",
    "    # Step 2: Make the predictions\n",
    "    Y_pred_base, prediction_time_base = model_prediction(X=X, model='baseline', batch_size=128, device=DEVICE)\n",
    "    \n",
    "    # Step 3: Encoding (POSITIVE_CLASS ('gibbon') -> 1, NEGATIVE_CLASS ('no-gibbon' -> 0)\n",
    "    Y[Y == POSITIVE_CLASS] = 1\n",
    "    Y[Y == NEGATIVE_CLASS] = 0\n",
    "    Y = Y.astype(int)\n",
    "    \n",
    "    # Step 4: Turn prob into preds (0, 1) and compute F1-score\n",
    "    Y_pred_base = np.argmax(Y_pred_base, axis=1)\n",
    "    f1_base = f1_score(y_true=Y, y_pred=Y_pred_base)\n",
    "    \n",
    "    # Step 5: Calculate FLOPs, MACs, Number of params\n",
    "    flops_base, macs_base, params_base = calc_flops(model='baseline', batch_size=1, device=DEVICE)\n",
    "\n",
    "    # Delete X, Y to save memory\n",
    "    del X, Y\n",
    "\n",
    "    ## Inference on ESO\n",
    "    X, Y, dataset_creation_time_eso = _create_data('eso')\n",
    "    Y_pred_eso, prediction_time_eso = model_prediction(X=X, model='eso', batch_size=128, device=DEVICE)\n",
    "\n",
    "    # The labels are only used for performance metrics calculation here\n",
    "    Y[Y == POSITIVE_CLASS] = 1\n",
    "    Y[Y == NEGATIVE_CLASS] = 0\n",
    "    Y = Y.astype(int)\n",
    "\n",
    "    Y_pred_eso = np.argmax(Y_pred_eso, axis=1)\n",
    "    f1_eso = f1_score(y_true=Y, y_pred=Y_pred_eso)\n",
    "\n",
    "    flops_eso, macs_eso, params_eso = calc_flops(model='eso', batch_size=1, device=DEVICE)\n",
    "    del X, Y\n",
    "\n",
    "    ## Save results to Pandas DataFrame\n",
    "    df = pd.DataFrame()\n",
    "    df['Durations'] = [\"Dataset Creation\", \"Prediction\", \"F1 Score\", \"Flops\", \"Macs\", \"Params\"]\n",
    "    df['Baseline'] = [dataset_creation_time_base, prediction_time_base, f1_base,\n",
    "                      flops_base, macs_base, params_base]\n",
    "    df['ESO'] = [dataset_creation_time_eso, prediction_time_eso, f1_eso, \n",
    "                 flops_eso, macs_eso, params_eso]\n",
    "\n",
    "    # Calculate improvement in percentage\n",
    "    df['Reduction'] = ((df['Baseline'] - df['ESO']) / df['Baseline']) * 100\n",
    "    \n",
    "    # Store results\n",
    "    df.to_csv('inference.csv')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddcd944-853e-4b2f-ba69-fac8e271ff86",
   "metadata": {},
   "source": [
    "### Testing everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31072ffe-ecff-4e18-a1b6-543aa28f169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Dataset for model: baseline ---\n",
      "Found file HGSM3AB_0+1_20160305_055900\n",
      "867\n",
      "(array(['gibbon', 'no-gibbon'], dtype='<U9'), array([178, 689]))\n",
      "--- Dataset created in 21.828219890594482 seconds ---\n",
      "--- Predicted Baseline in 0.6067299842834473 seconds ---\n",
      "--- Creating Dataset for model: eso ---\n",
      "Found file HGSM3AB_0+1_20160305_055900\n",
      "867\n",
      "(array(['gibbon', 'no-gibbon'], dtype='<U9'), array([178, 689]))\n",
      "--- Dataset created in 12.603198051452637 seconds ---\n",
      "--- Predicted ESO in 0.17692184448242188 seconds ---\n"
     ]
    }
   ],
   "source": [
    "df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84ab2f96-186c-4160-a55b-dfef02450279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Durations</th>\n",
       "      <th>Baseline</th>\n",
       "      <th>ESO</th>\n",
       "      <th>Reduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset Creation</td>\n",
       "      <td>2.182822e+01</td>\n",
       "      <td>1.260320e+01</td>\n",
       "      <td>42.261906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prediction</td>\n",
       "      <td>6.067300e-01</td>\n",
       "      <td>1.769218e-01</td>\n",
       "      <td>70.840102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>8.516746e-01</td>\n",
       "      <td>8.636364e-01</td>\n",
       "      <td>-1.404494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flops</td>\n",
       "      <td>9.013114e+06</td>\n",
       "      <td>2.943298e+06</td>\n",
       "      <td>67.344272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Macs</td>\n",
       "      <td>4.406336e+06</td>\n",
       "      <td>1.438784e+06</td>\n",
       "      <td>67.347383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Params</td>\n",
       "      <td>1.322340e+05</td>\n",
       "      <td>3.853800e+04</td>\n",
       "      <td>70.856209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Durations      Baseline           ESO  Reduction\n",
       "0  Dataset Creation  2.182822e+01  1.260320e+01  42.261906\n",
       "1        Prediction  6.067300e-01  1.769218e-01  70.840102\n",
       "2          F1 Score  8.516746e-01  8.636364e-01  -1.404494\n",
       "3             Flops  9.013114e+06  2.943298e+06  67.344272\n",
       "4              Macs  4.406336e+06  1.438784e+06  67.347383\n",
       "5            Params  1.322340e+05  3.853800e+04  70.856209"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e70e271-d655-41c5-b503-256d2ad8106d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Durations       Params\n",
       "Baseline      132234.0\n",
       "ESO            38538.0\n",
       "Reduction    70.856209\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trainable paramters \n",
    "df.loc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62d886b9-d1dc-4bee-ae35-03a6ad54f647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Durations        Flops\n",
       "Baseline     9013114.0\n",
       "ESO          2943298.0\n",
       "Reduction    67.344272\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of FLOPS\n",
    "df.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a696ae0e-77e9-4418-8aed-793f1d828c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Durations         Macs\n",
       "Baseline     4406336.0\n",
       "ESO          1438784.0\n",
       "Reduction    67.347383\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of MACS\n",
    "df.loc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420893f3-bdbb-4838-a4a9-bda86fb361c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
